{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN+w7WGSogyOAW7OhEf8vB/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","\n","# Load datasets\n","dynamic_data = pd.read_csv('/mnt/data/dynamic.csv')\n","static_data = pd.read_csv('/mnt/data/[static] id_adm_y.csv')"],"metadata":{"id":"tDguLOV08Con"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the number of records per patient\n","records_per_patient = dynamic_data.groupby('id').size()\n","\n","# Get summary statistics for the distribution of records per patient\n","distribution_summary = records_per_patient.describe()\n","distribution_summary, records_per_patient.value_counts().sort_index().head(10)"],"metadata":{"id":"ec9NnCeKEpE7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the 6h time_slot\n","\n","dynamic_data['charttime'] = pd.to_datetime(dynamic_data['charttime'])\n","static_data['icu_intime'] = pd.to_datetime(static_data['icu_intime'])\n","\n","# Merge dynamic data with static data on 'id' to get the ICU admission times\n","merged_data = pd.merge(dynamic_data, static_data[['id', 'icu_intime']], on='id', how='left')\n","\n","# Calculate time difference in hours\n","merged_data['time_diff'] = (merged_data['charttime'] - merged_data['icu_intime']).dt.total_seconds() / 3600\n","\n","# Define time slots based on time difference\n","def time_slot(time_diff):\n","    if time_diff >= 0:\n","        return int(time_diff // 6) + 1\n","    else:\n","        return -(-time_diff // 6)\n","\n","merged_data['time_slot'] = merged_data['time_diff'].apply(time_slot)\n","\n","# Select the latest record for each time slot per patient\n","final_data = merged_data.sort_values(by='charttime').groupby(['id', 'time_slot']).last().reset_index()\n","\n","# Remove rows with negative 'time_slot' values & above 5 (typo or future ICU admission)\n","positive_below5_time_slots = final_data[final_data['time_slot'] > 0 & < 5]"],"metadata":{"id":"6HgrEy5s8Dbj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove columns with above 30% missingness\n","\n","# Calculate the fraction of missing values for each column\n","missing_fraction = positive_below5_time_slots.isnull().mean()\n","\n","# Remove columns with a fraction of missingness above 30%\n","filtered_data = positive_below5_time_slots.loc[:, missing_fraction < 0.3]\n","\n","# Remove the column \"charttime\"\n","filtered_data = filtered_data.drop(columns=['charttime'])"],"metadata":{"id":"BlS4X6X38DeD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Forward imputation for each individual\n","# Group the data by 'id' to ensure imputation is done within each individual\n","df_imputed = df.groupby('id').apply(lambda group: group.fillna(method='ffill')).reset_index(drop=True)\n"],"metadata":{"id":"SfjHKCHQ9BLe"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u1NmENGVWpb5"},"outputs":[],"source":["# MICE for the rest missing value (with no \"recent\" value)\n","\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.linear_model import LinearRegression\n","\n","# Define the MICE imputer with provided parameters\n","mice_imputer = IterativeImputer(estimator=LinearRegression(), max_iter=10, random_state=0)\n","\n","# Columns to be imputed using MICE (excluding 'id', 'time_slot', and 'charttime')\n","columns_to_impute = df_imputed.columns.difference(['id', 'time_slot', 'charttime'])\n","\n","# Perform MICE imputation on the dataset\n","df_mice_imputed = df_imputed.copy()\n","df_mice_imputed[columns_to_impute] = mice_imputer.fit_transform(df_imputed[columns_to_impute])\n"]},{"cell_type":"code","source":["## Deal with outliers\n","\n","# Plot of original value\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Set the style of the visualization\n","sns.set(style=\"whitegrid\")\n","\n","# Plotting distributions of each variable (except the first 3 columns)\n","fig, axes = plt.subplots(nrows=len(columns_to_standardize)//3, ncols=3, figsize=(18, 20))\n","fig.tight_layout(pad=5.0)\n","\n","for i, col in enumerate(columns_to_standardize):\n","    row = i // 3\n","    col_num = i % 3\n","    sns.histplot(df_new[col], kde=True, ax=axes[row, col_num])\n","    axes[row, col_num].set_title(col)\n","\n","# Adjust layout to make room for titles and prevent overlap\n","plt.subplots_adjust(top=0.95)\n","plt.suptitle('Distribution of Variables in the Dataset', fontsize=16)\n","plt.show()\n"],"metadata":{"id":"XXMfQMK9Egwl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plotting of s.d.\n","\n","fig, axes = plt.subplots(nrows=len(columns_to_standardize)//3, ncols=3, figsize=(18, 20))\n","fig.tight_layout(pad=5.0)\n","\n","for i, (column, outliers) in enumerate(outliers_dict.items()):\n","    if not outliers.empty:\n","        # Calculate the deviations\n","        mean = df_new[column].mean()\n","        std = df_new[column].std()\n","        deviations = (outliers[column] - mean) / std\n","\n","        # Separate positive and negative deviations\n","        pos_dev = deviations[deviations > 0]\n","        neg_dev = deviations[deviations < 0]\n","\n","        # Plot\n","        row = i // 3\n","        col_num = i % 3\n","        sns.histplot(pos_dev, ax=axes[row, col_num], bins=30, kde=False, color='blue', label='Positive Deviation')\n","        sns.histplot(neg_dev, ax=axes[row, col_num], bins=30, kde=False, color='red', label='Negative Deviation')\n","        axes[row, col_num].set_title(f'Deviation Distribution for {column}')\n","        axes[row, col_num].set_xlabel('Deviation (number of standard deviations)')\n","        axes[row, col_num].legend()\n","\n","# Adjust layout to make room for titles and prevent overlap\n","plt.subplots_adjust(top=0.95)\n","plt.suptitle('Distribution of Positive and Negative Deviations for Outliers in Each Variable', fontsize=16)\n","plt.show()\n","\n","\n","# Function to calculate the fraction of outliers for each variable\n","def calculate_outlier_fractions(dataframe, outliers_dict):\n","    outlier_fractions = {}\n","    total_count = len(dataframe)\n","    for column, outliers in outliers_dict.items():\n","        if not outliers.empty:\n","            # Calculate fraction of outliers for the column\n","            outlier_count = len(outliers)\n","            fraction = outlier_count / total_count\n","            outlier_fractions[column] = fraction\n","\n","    return outlier_fractions\n","\n","# Calculate and display the fraction of outliers for each variable\n","outlier_fractions = calculate_outlier_fractions(df_new, outliers_dict)\n","outlier_fractions"],"metadata":{"id":"oPvTHqJ9JCwR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to mark outliers as NaN that exceed a threshold of standard deviations from the mean\n","def mark_outliers_as_nan(dataframe, columns, threshold=5):\n","    updated_dataframe = dataframe.copy()\n","    for column in columns:\n","        mean = updated_dataframe[column].mean()\n","        std = updated_dataframe[column].std()\n","\n","        # Define the upper and lower bounds\n","        lower_bound = mean - threshold * std\n","        upper_bound = mean + threshold * std\n","\n","        # Mark outliers as NaN\n","        updated_dataframe[column] = updated_dataframe[column].mask((updated_dataframe[column] < lower_bound) | (updated_dataframe[column] > upper_bound))\n","\n","    return updated_dataframe\n","\n","# Mark outliers that exceed 5 standard deviations from the mean as NaN for each variable\n","df_marked_outliers = mark_outliers_as_nan(df_new, columns_to_standardize)\n"],"metadata":{"id":"sIc8N-uaBW6W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the MICE imputer with specified parameters\n","mice_imputer_with_params = IterativeImputer(estimator=LinearRegression(), max_iter=10, random_state=0)\n","\n","# Perform MICE imputation on the dataset, focusing on columns to impute\n","df_mice_imputed_with_params = df_with_marked_outliers.copy()\n","df_mice_imputed_with_params[columns_to_standardize] = mice_imputer_with_params.fit_transform(df_with_marked_outliers[columns_to_standardize])"],"metadata":{"id":"Ju_Hk8x1PC7_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make the time_step consistent & remove individuals with only 1 record\n","\n","# Group by 'patient' and count the number of rows for each patient\n","grouped_all = df.groupby('patient').size()\n","\n","# Find patients with only one record\n","patients_with_one_row = grouped_all[grouped_all == 1]\n","\n","# The length of this series will give us the number of individuals who only have one row\n","num_individuals_one_row = len(patients_with_one_row)\n","print(num_individuals_one_row)\n","\n","\n","removed_individuals_ids = patients_with_one_row.index.tolist()\n","df_cleaned = df[~df['patient'].isin(patients_with_one_row.index)]\n","\n","# Return the number of rows in the cleaned dataset and a sample of the removed IDs\n","len(df_cleaned), removed_individuals_ids[:5]  # Displaying first 5 IDs as a sample\n","\n","\n","\n","\n"],"metadata":{"id":"WFHOgraFmEPL"},"execution_count":null,"outputs":[]}]}